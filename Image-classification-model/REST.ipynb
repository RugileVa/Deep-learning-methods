{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UqUhj1FTOWyE"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn.functional as F\n",
        "\n",
        "DIM = 32\n",
        "CH = 3\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, num_classes=3):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels=CH, out_channels=32, kernel_size=3, padding=1)\n",
        "        self.batchnorm1 = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1)\n",
        "        self.batchnorm2 = nn.BatchNorm2d(32)\n",
        "        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
        "        self.dropout1 = nn.Dropout2d(p=0.2)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
        "        self.batchnorm3 = nn.BatchNorm2d(64)\n",
        "        self.conv4 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
        "        self.batchnorm4 = nn.BatchNorm2d(64)\n",
        "        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n",
        "        self.dropout2 = nn.Dropout2d(p=0.3)\n",
        "\n",
        "        self.conv5 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
        "        self.batchnorm5 = nn.BatchNorm2d(128)\n",
        "        self.conv6 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
        "        self.batchnorm6 = nn.BatchNorm2d(128)\n",
        "        self.maxpool3 = nn.MaxPool2d(kernel_size=2)\n",
        "        self.dropout3 = nn.Dropout2d(p=0.4)\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(128 * (DIM // 8) * (DIM // 8), 128)\n",
        "        self.batchnorm_fc = nn.BatchNorm1d(128)\n",
        "        self.dropout_fc = nn.Dropout(p=0.5)\n",
        "        self.fc2 = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.conv1(x))\n",
        "        x = self.batchnorm1(x)\n",
        "        x = torch.relu(self.conv2(x))\n",
        "        x = self.batchnorm2(x)\n",
        "        x = self.maxpool1(x)\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        x = torch.relu(self.conv3(x))\n",
        "        x = self.batchnorm3(x)\n",
        "        x = torch.relu(self.conv4(x))\n",
        "        x = self.batchnorm4(x)\n",
        "        x = self.maxpool2(x)\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        x = torch.relu(self.conv5(x))\n",
        "        x = self.batchnorm5(x)\n",
        "        x = torch.relu(self.conv6(x))\n",
        "        x = self.batchnorm6(x)\n",
        "        x = self.maxpool3(x)\n",
        "        x = self.dropout3(x)\n",
        "\n",
        "        x = self.flatten(x)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.batchnorm_fc(x)\n",
        "        x = self.dropout_fc(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# Define your model\n",
        "model = Net(num_classes=3)"
      ],
      "metadata": {
        "id": "7OKj82S9OhVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the saved model\n",
        "model = Net()\n",
        "model_weights = torch.load('/content/drive/MyDrive/modelwithtorch5.pth', map_location=torch.device('cpu'))\n",
        "model.load_state_dict(model_weights)"
      ],
      "metadata": {
        "id": "mYvUydv7OX6k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b9b1fbd-0390-414f-b956-1cba950348c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_transforms = {\n",
        "    'test': transforms.Compose([\n",
        "        transforms.Resize((32, 32)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
        "    ])\n",
        "}"
      ],
      "metadata": {
        "id": "z7IO4eS0Pk76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flask flask-restful flask-swagger flask-swagger-ui flask-cors pyngrok"
      ],
      "metadata": {
        "id": "tRFphclIOcv3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok authtoken  # should put your own authtoken to ngrok for flask to work from google colab"
      ],
      "metadata": {
        "id": "m0b1wKa8OtvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# REST api\n",
        "from flask import Flask, request, jsonify\n",
        "from flask_restful import Api, Resource, reqparse\n",
        "from flask_swagger_ui import get_swaggerui_blueprint\n",
        "from flask_swagger import swagger\n",
        "from pyngrok import ngrok\n",
        "import io\n",
        "from PIL import Image\n",
        "import base64\n",
        "from flask_cors import CORS\n",
        "from werkzeug.datastructures import FileStorage\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class_names = ['car', 'cat', 'pizza']\n",
        "\n",
        "app = Flask(__name__)\n",
        "api = Api(app)\n",
        "CORS(app, resources={r\"*\": {\"origins\": \"*\"}})\n",
        "model = model.to('cpu')\n",
        "model.eval()\n",
        "\n",
        "def preprocess_image(image_file):\n",
        "    image = Image.open(image_file)\n",
        "    transformed_image = data_transforms['test'](image)\n",
        "    return transformed_image.unsqueeze(0)\n",
        "\n",
        "# Define a class for prediction\n",
        "class Prediction(Resource):\n",
        "    def post(self):\n",
        "      try:\n",
        "        # Get the image from the request\n",
        "        file = request.files.get(\"file\")\n",
        "        if not file:\n",
        "            return jsonify({\"error\": \"No image provided\"}), 400\n",
        "\n",
        "        # Preprocess the image\n",
        "        processed_image = preprocess_image(file)\n",
        "        processed_image = processed_image.to('cpu')\n",
        "\n",
        "        # Make a prediction using the model\n",
        "        with torch.no_grad():\n",
        "            output = model(processed_image)\n",
        "            output_softmax = F.softmax(output, dim=1)\n",
        "            conf, predicted_idx = torch.max(output_softmax.data, 1)\n",
        "\n",
        "        # Prepare the response\n",
        "        response = {\n",
        "            \"class_name\": class_names[predicted_idx.item()],\n",
        "            \"confidence\": f\"{conf.item() * 100:.2f}%\"\n",
        "        }\n",
        "\n",
        "      except Exception as e:\n",
        "        print(\"Error processing request:\", e)\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "      return jsonify(response)\n",
        "\n",
        "\n",
        "# Add resource to API\n",
        "api.add_resource(Prediction, '/predict')\n",
        "\n",
        "# Generate Swagger/OpenAPI spec\n",
        "@app.route(\"/spec\")\n",
        "def spec():\n",
        "    swag = {\n",
        "        'swagger': '2.0',\n",
        "        'info': {\n",
        "            'title': 'Image Prediction API',\n",
        "            'version': '1.0'\n",
        "        },\n",
        "        'paths': {\n",
        "            '/predict': {\n",
        "                'post': {\n",
        "                    'summary': 'Predict class of an image',\n",
        "                    'description': 'Upload an image file to predict its class.',\n",
        "                    'consumes': [\n",
        "                        'multipart/form-data'\n",
        "                    ],\n",
        "                    'produces': [\n",
        "                        'application/json'\n",
        "                    ],\n",
        "                    'parameters': [\n",
        "                        {\n",
        "                            'name': 'file',\n",
        "                            'in': 'formData',\n",
        "                            'type': 'file',\n",
        "                            'required': True,\n",
        "                            'description': 'Image file to predict'\n",
        "                        }\n",
        "                    ],\n",
        "                    'responses': {\n",
        "                        '200': {\n",
        "                            'description': 'Prediction successful',\n",
        "                            'schema': {\n",
        "                                'type': 'object',\n",
        "                                'properties': {\n",
        "                                    'class_name': {\n",
        "                                        'type': 'string',\n",
        "                                        'description': 'Predicted class name'\n",
        "                                    },\n",
        "                                    'confidence': {\n",
        "                                        'type': 'string',\n",
        "                                        'format': 'byte',\n",
        "                                        'description': 'Predicted class name'\n",
        "                                    }\n",
        "                                }\n",
        "                            }\n",
        "                        }\n",
        "                    }\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "    return swag\n",
        "\n",
        "# Swagger UI configuration\n",
        "SWAGGER_URL = '/api/docs'  # URL for accessing Swagger UI (without trailing '/')\n",
        "API_URL = '/spec'  # Our API url (can be of a local server, like '/apidocs')\n",
        "\n",
        "# Call factory function to create our blueprint\n",
        "swagger_ui_blueprint = get_swaggerui_blueprint(\n",
        "    SWAGGER_URL,  # Swagger UI static files will be mapped to '{SWAGGER_URL}/dist/'\n",
        "    API_URL,\n",
        "    config={  # Swagger UI config overrides\n",
        "        'app_name': \"Image Prediction API\"\n",
        "    },\n",
        ")\n",
        "\n",
        "app.register_blueprint(swagger_ui_blueprint, url_prefix=SWAGGER_URL)\n",
        "\n",
        "# Set up pyngrok\n",
        "ngrok_tunnel = ngrok.connect(5000)\n",
        "print(\"Public URL:\", ngrok_tunnel.public_url)\n",
        "\n",
        "# Run the Flask app\n",
        "app.run(port=5000)"
      ],
      "metadata": {
        "id": "Srd0c9UnOuRB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}